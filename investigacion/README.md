# Investigaci贸n y Datos

Recursos para investigadores, acceso a papers, datasets abiertos y referencias acad茅micas.

##  Recursos de Investigaci贸n en Argentina

| Recurso | Entidad | Descripci贸n | Link |
| --- | --- | --- | --- |
| **Datos Argentina** | Naci贸n | Portal nacional de datos abiertos. | [Web](https://datos.gob.ar/) |
| **BA Data** | GCBA | Datos abiertos de la Ciudad de Buenos Aires. | [Web](https://data.buenosaires.gob.ar/) |
| **CONICET Digital** | CONICET | Repositorio institucional del CONICET. | [Web](https://ri.conicet.gov.ar/) |
| **SNRD** | MinCyT | Sistema Nacional de Repositorios Digitales. | [Web](https://repositoriosdigitales.mincyt.gob.ar/) |
| **INDEC** | Naci贸n | Instituto Nacional de Estad铆stica y Censos. | [Web](https://www.indec.gob.ar/) |

---

##  Datasets Globales

Recopilaciones de datos masivos para entrenamiento de modelos.

*   **Hugging Face Datasets:** [Hugging Face Hub](https://huggingface.co/datasets) - La colecci贸n m谩s grande y moderna de datasets para NLP, Vision y Audio. Es el est谩ndar actual.
*   **Kaggle Datasets:** [Kaggle](https://www.kaggle.com/datasets) - Datasets variados, competiciones y notebooks de ejemplo.
*   **Google Dataset Search:** [Google](https://datasetsearch.research.google.com/) - "Google Scholar" pero para datasets.
*   **Papers with Code:** [Datasets](https://paperswithcode.com/datasets) - Datasets organizados por tarea y vinculados a benchmarks (SOTA).
*   **Common Crawl:** [Web](https://commoncrawl.org/) - Archivo de la web, base para entrenar la mayor铆a de los LLMs.

---

##  Papers Fundamentales (Modern AI)

Selecci贸n de papers que marcaron un antes y un despu茅s en la era del Deep Learning y LLMs.

### LLMs & Transformers
*   **Attention Is All You Need (2017):** [Arxiv](https://arxiv.org/abs/1706.03762) - El paper que introdujo la arquitectura Transformer.
*   **BERT: Pre-training of Deep Bidirectional Transformers (2018):** [Arxiv](https://arxiv.org/abs/1810.04805)
*   **GPT-3: Language Models are Few-Shot Learners (2020):** [Arxiv](https://arxiv.org/abs/2005.14165)
*   **Llama 2: Open Foundation and Fine-Tuned Chat Models (2023):** [Arxiv](https://arxiv.org/abs/2307.09288)

### Computer Vision
*   **ResNet (Deep Residual Learning) (2015):** [Arxiv](https://arxiv.org/abs/1512.03385)
*   **YOLO (You Only Look Once) (2015):** [Arxiv](https://arxiv.org/abs/1506.02640)
*   **ViT (An Image is Worth 16x16 Words) (2020):** [Arxiv](https://arxiv.org/abs/2010.11929)

### Motores de B煤squeda Acad茅mica
*   [Google Scholar](https://scholar.google.com/)
*   [Semantic Scholar](https://www.semanticscholar.org/) - B煤squeda sem谩ntica de papers con grafos de citas.
*   [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/) - Herramienta (creada por A. Karpathy) para filtrar y encontrar papers relevantes en Arxiv.
